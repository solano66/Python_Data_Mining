# -*- coding: utf-8 -*-
"""Outliers Detection methods.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r4VSSJCdf4gPNR_F2RoH3f33SraYhb6c
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import statsmodels.api as sm
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.ensemble import IsolationForest
from sklearn import datasets
from scipy.stats import iqr
from scipy.cluster.vq import kmeans, vq
from sklearn.neighbors import LocalOutlierFactor

# %matplotlib inline

sp_data = np.random.seed(3147)
# x = np.random.randint(low = 1, high = 10, size = 100)
sp_data = np.random.normal(0,1,1000)

x_df = pd.DataFrame(sp_data)

# x_df.info()
x_df.describe()

# create the displot
sns.displot(sp_data, kde = True)

# lebel the axis
plt.title("data distribution")
plt.show()

print("skewness: ",x_df.skew())
print("Kurtosis: ",x_df.kurt())

#create the boxplot
ax = sns.boxplot(x=sp_data)
ax.set_title("data boxplot", fontsize =20, pad = 20)

plt.show()

#extract the upper and lower quantiles
x_lq = x_df.quantile(0.25)
x_uq = x_df.quantile(0.75)
#extract the inter quartile range
x_iqr = x_uq - x_lq

#get the upper and lower bounds
lower_bound = x_lq - 1.5*x_iqr # -2.747416
upper_bound = x_uq + 1.5*x_iqr # 2.709666
# lower_bound

def x_outlier(data):
    list = []
    for dt in data:
        if dt > upper_bound:
            list.append(dt)
        elif dt < lower_bound:
            list.append(dt)
    return list

IQR_outliers = x_df[(x_df <= lower_bound) | (x_df >= upper_bound)]
print(len(IQR_outliers))

IQR_outliers.isna().sum()
# so there actual 6 value are not null

#calculate the Z score
x_df["1"] = (x_df - x_df.mean())/x_df.std()

#show the distribution plot
sns.displot(x_df["1"],
           kde = True)

plt.xlabel("index 1", fontsize = 15)
plt.ylabel("Count", fontsize = 15)
plt.title("data distribution", fontsize = 15)

plt.show()

data_outliers = x_df[abs(x_df["1"]) >= 3]
data_outliers

x = np.random.seed(3147)
# x = np.random.randint(low = 1, high = 10, size = 100)
x = np.random.normal(0,1,1000)
x_df = pd.DataFrame(x, columns=['x'])

y = np.random.normal(0,1,1000)
y_df = pd.DataFrame(y, columns=['y'])

#create the base axis
fig, ax = plt.subplots(1,1, figsize = (8,10))

#plot the scatter plot
ax.scatter(x_df, y_df)

#add labels
ax.set_xlabel("x", fontsize = 20, labelpad = 20)
ax.set_ylabel("y", fontsize = 20, labelpad = 20)
ax.set_title("data scatter plot", fontsize = 20, pad = 20)
#alter the tick parametes
ax.tick_params(axis = "both", labelsize = 20)

ax = sns.boxplot(data = [x_df, y_df], orient = "h", palette = "Set2")

ax.set_xlabel("Value", fontsize = 20, labelpad = 20)
ax.set_ylabel("Attributes", fontsize = 20, labelpad = 20)
ax.set_title("Boxplot data", fontsize = 20,
            pad = 20)
ax.tick_params(which = "both", labelsize = 15)

#create a function to calculate IQR bounds
def IQR_bounds(dataframe, column_name, multiple):
    """Extract the upper and lower bound for outlier detection using IQR
    
    Input:
        dataframe: Dataframe you want to extract the upper and lower bound from
        column_name: column name you want to extract upper and lower bound for
        multiple: The multiple to use to extract this
        
    Output:
        lower_bound = lower bound for column
        upper_bound = upper bound for column"""
    
    #extract the quantiles for the column
    lower_quantile = dataframe[column_name].quantile(0.25)
    upper_quantile = dataframe[column_name].quantile(0.75)
    #cauclat IQR
    IQR = upper_quantile - lower_quantile
    
    #extract lower and upper bound
    lower_bound = lower_quantile - multiple * IQR
    upper_bound = upper_quantile + multiple * IQR
    
    #retrun these values
    return lower_bound, upper_bound

x_s = x_df.squeeze()
y_s = y_df.squeeze()

xy_data = pd.concat([x_s, y_s], axis=1)
# xy_data

#set the columns we want
columns = ["x", "y"]
#create a dictionary to store the bounds
column_bounds = {}

#iteratre over each column to extract bounds
for column in columns:
    #extract normal and extreme bounds
    lower_bound, upper_bound =  IQR_bounds(xy_data, column, 1.5)
    lower_bound_extreme, upper_bound_extreme = IQR_bounds(xy_data, column, 3)
    #send them to the dictionary
    column_bounds[column] = [lower_bound, upper_bound,
                            lower_bound_extreme, upper_bound_extreme]

#create the normal dataframe
IQR_AD = xy_data[(xy_data["x"] < column_bounds["x"][0]) | 
                         (xy_data["x"] > column_bounds["x"][1]) |
                         (xy_data["y"] < column_bounds["y"][0]) | 
                         (xy_data["y"] > column_bounds["y"][1])
                        ]
#create the extreme dataframe
IQR_AD_extreme = xy_data[(xy_data["x"] < column_bounds["x"][2]) |
                         (xy_data["x"] > column_bounds["x"][3]) |
                         (xy_data["y"] < column_bounds["y"][2]) | 
                         (xy_data["y"] > column_bounds["y"][3])
                         ]

IQR_AD

# IQR_AD_extreme # will print none

#create the normal dataframe
xy_data["IQR_AD"] = ((xy_data["x"] < column_bounds["x"][0]) | 
                         (xy_data["x"] > column_bounds["x"][1]) |
                         (xy_data["y"] < column_bounds["y"][0]) | 
                         (xy_data["y"] > column_bounds["y"][1])
                    )

xy_data

count = 0
for na in xy_data.IQR_AD:
    if na == True:
        count+=1
print(count)
# there 13 value were the value is True

xy_data["IQR_AD"] = xy_data["IQR_AD"].apply(lambda x: str(1) if x == False else str(-1))

# np.shape(xy_data.y)
xy_data

#plot teh scatter plot
# fig = px.scatter(xy_data, x = "x", y = "y",
#           color = "IQR_AD", 
#           hover_name = "name")
fig = px.scatter(xy_data, x = "x", y = "y", color = "IQR_AD")
fig.update_layout(title = "IQR outlier detection",
                 title_x = 0.5)
fig.show()

from sklearn.ensemble import IsolationForest

#create the method instance
isf = IsolationForest(n_estimators = 100, random_state = 42, contamination = 0.02)
#use fit_predict on the data as we are using all the data
preds = isf.fit_predict(xy_data[["x", "y"]])
#extract outliers from the data
xy_data["iso_forest_outliers"] = preds
xy_data["iso_forest_outliers"] = xy_data["iso_forest_outliers"].astype(str)
#extract the scores from the data in terms of strength of outlier
xy_data["iso_forest_scores"] = isf.decision_function(xy_data[["x", "y"]])

#print how many outliers the data suggests
print(xy_data["iso_forest_outliers"].value_counts())

#this plot will be repeated so it is better to create a function
def scatter_plot(dataframe, x, y, color, title):
    """Create a plotly express scatter plot with x and y values with a colour
    
    Input:
        dataframe: Dataframe containing columns for x, y, colour and hover_name data
        x: The column to go on the x axis
        y: Column name to go on the y axis
        color: Column name to specify colour
        title: Title for plot
        hover_name: column name for hover
        
    Returns:
        Scatter plot figure
    """
    #create the base scatter plot
    fig = px.scatter(dataframe, x = x, y=y,
                    color = color)
    #set the layout conditions
    fig.update_layout(title = title,
                     title_x = 0.5)
    #show the figure
    fig.show()

#create scatter plot
scatter_plot(xy_data, "x", "y", "iso_forest_outliers",
             "Isolation Forest Outlier Detection")

#create the same plot focusing on the scores from the dataset
scatter_plot(xy_data, "x", "y", "iso_forest_scores",
             "Isolation Forest Outlier Detection Scores")

#create the distribution plot
sns.displot(xy_data["iso_forest_scores"],color='red',label='if',
           kde = True);

#set the title
plt.title('Distribution of Isolation Forest Scores', fontsize = 15, loc='center')
plt.xlabel("Isolation Forest Scores", fontsize = 15)
plt.ylabel("Count", fontsize = 15)

#show the result
plt.show()

#import the algorithm
from sklearn.neighbors import LocalOutlierFactor

#initialise the algorithm
lof = LocalOutlierFactor(n_neighbors = 20)
#fit it to the training data, since we don't use it for novelty than this is fine
y_pred = lof.fit_predict(xy_data[["x", "y"]])

#extract the predictions as strings
xy_data["lof_outliers"] = y_pred.astype(str)
#print the number of outliers relative to non-outliers
print(xy_data["lof_outliers"].value_counts())
#extract the outlier scores
xy_data["lof_scores"] = lof.negative_outlier_factor_

scatter_plot(xy_data, "x", "y", "lof_outliers",
             "Local Outlier Factor Outlier Detection")

scatter_plot(xy_data, "x", "y", "lof_scores",
             "Local Outlier Factor scores")

#create the distribution plot
sns.displot(xy_data["lof_scores"],color='red',label='if',
           kde = True);

#set the title
plt.title("Distribution of Local Outlier Factor Scores", fontsize = 15, loc='center', pad = 20)
plt.xlabel("Local Outlier Factor", fontsize = 15, labelpad = 20)
plt.ylabel("Count", fontsize = 15, labelpad = 20)

#show the result
plt.show()

#import the algorithm
from sklearn.cluster import DBSCAN

#initiate the algorithm
#set the distance to 20, and min_samples as 5
outlier_detection = DBSCAN(eps = 20, metric = "euclidean", min_samples = 10, n_jobs = -1)
#fit_predict the algorithm to the existing data
clusters = outlier_detection.fit_predict(xy_data[["x", "y"]])

#extract the labels from the algorithm
xy_data["dbscan_outliers"] = clusters
#label all others as inliers 
xy_data["dbscan_outliers"] = xy_data["dbscan_outliers"].apply(lambda x: str(1) if x>-1 else str(-1))
#print the vaue counts
print(xy_data["dbscan_outliers"].value_counts())

# using DBSCan there is no found outliers

scatter_plot(xy_data, "x", "y", "dbscan_outliers",
             "DBScan Outlier Detection")

#import the required library
from sklearn import svm

#initiate the model
svm_model = svm.OneClassSVM(nu = 0.2, kernel = "rbf", gamma = "auto")
#apply the model to the data
outliers = svm_model.fit_predict(xy_data[["x", "y"]])

#extract the labels
xy_data["ocsvm_outliers"] = outliers
#change the labels
xy_data["ocsvm_outliers"] = xy_data["ocsvm_outliers"].apply(lambda x: str(-1) if x == -1 else str(1))
#extract the score
xy_data["ocsvm_scores"] = svm_model.score_samples(xy_data[["x", "y"]])
#print the value counts for inlier and outliers
print(xy_data["ocsvm_outliers"].value_counts())

scatter_plot(xy_data, "x", "y", "ocsvm_outliers",
             "One Class SVM Outlier Detection")
# The outliers is the blue one

#import the necessary library and functionality
from sklearn.covariance import EllipticEnvelope

#create the model, set the contamination as 0.02
EE_model = EllipticEnvelope(contamination = 0.02)
#implement the model on the data
outliers = EE_model.fit_predict(xy_data[["x", "y"]])

#extract the labels
xy_data["EE_outliers"] = outliers
#change the labels
xy_data["EE_outliers"] = xy_data["EE_outliers"].apply(lambda x: str(-1) if x == -1 else str(1))
#extract the score
xy_data["EE_scores"] = EE_model.score_samples(xy_data[["x", "y"]])
#print the value counts for inlier and outliers
print(xy_data["EE_outliers"].value_counts())

#plot the results
scatter_plot(xy_data, "x", "y", "EE_outliers",
             "Elliptic Envelope Outlier Detection")

#plot the scores
scatter_plot(xy_data, "x", "y", "EE_scores",
             "Elliptic Envelope scores")

#extract the sum of the outlier count
xy_data['outliers_sum'] = (xy_data['iso_forest_outliers'].astype(int)+
                           xy_data['lof_outliers'].astype(int)+
                           xy_data['dbscan_outliers'].astype(int)+
                          xy_data['EE_outliers'].astype(int))
#print the value counts for each scale
print(xy_data["outliers_sum"].value_counts())

def count_the_detection_outliers(column_data):
    """
    count the outlier detected by the dbscan algorithm
    """
    cnt = 0
    for n in column_data:
        if n == -1:
            cnt += 1
    return cnt

# xy_data.info()

iso_forest = count_the_detection_outliers(xy_data['iso_forest_outliers'].astype(float))
lof = count_the_detection_outliers(xy_data['lof_outliers'].astype(float))
dbscan = count_the_detection_outliers(xy_data['dbscan_outliers'].astype(float))
ee_out = count_the_detection_outliers(xy_data['EE_outliers'].astype(float))

print("iso forest : ",iso_forest)
print("lof        : ",lof)
print("dbscan     : ",dbscan)
print("ee_out     : ",ee_out)

# we can see the comparison how each algorithm detect each outliers

scatter_plot(xy_data, "x", "y", "outliers_sum",
             "Ensemble outlier detection")

